{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Read in datafiles\n",
    "training_data = np.loadtxt('./data/pa2train.txt')\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Read in datafiles\n",
    "validation_data = np.loadtxt('./data/pa2validation.txt')\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Read in datafiles\n",
    "test_data = np.loadtxt('./data/pa2test.txt')\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating info gain\n",
    "def info_gain(subset, feature, threshold, label):\n",
    "    \n",
    "    num_samples = len(subset)\n",
    "    # Partition Subset into two sets v1, v2\n",
    "    v1, v2 = [x for x in subset if x[feature] < threshold], [x for x in subset if x[feature] >= threshold]\n",
    "    v1_samples, v2_samples = len(v1), len(v2)\n",
    "    \n",
    "    # Find distribution of labels for both partitions\n",
    "    v1_default, v2_default = len([x for x in v1 if x[label] == 1]), len([x for x in v2 if x[label] == 0])\n",
    "    v1_no_default, v2_no_default = (v1_samples - v1_default), (v2_samples - v2_default)\n",
    "    \n",
    "    # Compare distribution of labels in both subsets, P(Z=z)\n",
    "    p_yes_threshold =  (v2_samples/num_samples)\n",
    "    p_no_threshold = (1 - p_yes_threshold)\n",
    "    \n",
    "    # Calculate conditional entropy for sboth partitions H(X|Z=z)\n",
    "    if v1_default == 0 or v1_no_default == 0: \n",
    "        if v1_samples == 0: \n",
    "            cond_entropy_no = 0\n",
    "        elif v1_default == 0: \n",
    "            cond_entropy_no = ((v1_no_default/len(v1))*math.log(v1_no_default/len(v1)))\n",
    "        else: \n",
    "            cond_entropy_no = ((v1_default/len(v1))*math.log(v1_default/len(v1)))\n",
    "    else:\n",
    "        cond_entropy_no = -(((v1_no_default/len(v1))*math.log(v1_no_default/len(v1)))+((v1_default/len(v1))*math.log(v1_default/len(v1))))\n",
    "        # Calculate conditional entropy for sboth partitions H(X|Z=z)\n",
    "    \n",
    "    if v2_default == 0 or v2_no_default == 0: \n",
    "        if v2_samples == 0: \n",
    "            cond_entropy_yes = 0\n",
    "        elif v2_default == 0: \n",
    "            cond_entropy_yes = ((v2_no_default/len(v2))*math.log(v2_no_default/len(v2)))\n",
    "        else: \n",
    "            cond_entropy_yes = ((v2_default/len(v2))*math.log(v2_default/len(v2)))\n",
    "    else:\n",
    "        cond_entropy_yes = -(((v2_default/len(v2))*math.log(v2_default/len(v2)))+((v2_no_default/len(v2))*math.log(v2_no_default/len(v2)))) \n",
    "    \n",
    "    # return overall conditional entropy H(X|Z)\n",
    "    return (cond_entropy_yes*(len(v2)/num_samples) + cond_entropy_no*(len(v1)/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function for Obtaining threshold values\n",
    "def get_thresholds(feature_vals):\n",
    "    thresholds = []\n",
    "    features = sorted(set(feature_vals))\n",
    "    for i in range(1,len(features)): \n",
    "        thresholds.append((feature_vals[i-1]+feature_vals[i])/2)\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_threshold(feature, threshold, data): \n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    left_partition = np.empty((0,0))\n",
    "    right_partition = np.empty((0,0))\n",
    "    for i in range(rows): \n",
    "        if data[i,feature] < threshold: \n",
    "            if left_partition.shape == (0,0): \n",
    "                left_partition = np.array(data[i,:])\n",
    "                left_partition = left_partition.reshape((1,cols))\n",
    "            else: \n",
    "                # Add to \"No\" partition\n",
    "                left_partition = np.vstack((left_partition,data[i,:]))\n",
    "        elif data[i,feature] >= threshold: \n",
    "            if right_partition.shape == (0,0): \n",
    "                right_partition = np.array(data[i,:])\n",
    "                right_partition = right_partition.reshape((1,cols))\n",
    "            else: \n",
    "                # Add to \"Yes\" partition\n",
    "                right_partition = np.vstack((right_partition,data[i,:]))\n",
    "    return right_partition, left_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_decision_rule(training_samples): \n",
    "    # Pick feature, threshold pair that maxes info gain \n",
    "    split_rule = {}\n",
    "    for i in range(training_samples.shape[1]-1):\n",
    "        feature_dict = {}\n",
    "        # Obtain thresholds\n",
    "        thresholds = get_thresholds(training_samples[:,i])\n",
    "        for threshold in thresholds: \n",
    "            # Calculate info gain for threshold-feature pair\n",
    "            ig = info_gain(training_samples, i, threshold, training_samples.shape[1]-1)\n",
    "            # Append to dictionary \n",
    "            feature_dict[ig] = (i, threshold)\n",
    "            # Use feature-threshold pair with max info gain\n",
    "            max_ig = sorted(feature_dict.keys())[0]\n",
    "            feature_threshold = feature_dict[max_ig]\n",
    "            split_rule[max_ig] = feature_threshold      \n",
    "    # Find final split rule\n",
    "    split = split_rule[sorted(split_rule.keys())[0]]\n",
    "    return (split[0],split[1]), sorted(split_rule.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Decision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision Tree Node Class\n",
    "class decisionTreeNode: \n",
    "        \n",
    "    # Define constructor\n",
    "    def __init__(self, data):\n",
    "        self.children = []\n",
    "        self.pure = False\n",
    "        self.feature = 0\n",
    "        self.threshold = 0\n",
    "        self.data = data\n",
    "        self.predicted_label = None\n",
    "        self.entropy = float(0.0)\n",
    "        \n",
    "    def isPure(self, label): \n",
    "        isPure = False\n",
    "        labels = [x[label] for x in self.data]\n",
    "        # Check if labels for node are pure\n",
    "        if len(set(labels)) == 1: \n",
    "            isPure = True\n",
    "        return isPure\n",
    "\n",
    "# Define Decision Tree\n",
    "class decisionTree: \n",
    "    # Define Decision Tree Constructor\n",
    "    def __init__(self, training_data):\n",
    "        label_col = (training_data.shape[1] - 1)\n",
    "        self.root = decisionTreeNode(training_data)\n",
    "        self.impure_leaf_nodes = [self.root]\n",
    "        '''\n",
    "        if self.root.isPure(label_col) == False: \n",
    "            self.impure_leaf_nodes.append(self.root)\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    # Function for building decision tree\n",
    "    def train(self, training_data): \n",
    "        label_index = (training_data.shape[1] - 1)\n",
    "        # Continue Algorithm until all leaf nodes are pure\n",
    "        while len(self.impure_leaf_nodes) != 0: \n",
    "            # Pick an impure node V and remove from list\n",
    "            parent_node = self.impure_leaf_nodes[-1]\n",
    "            self.impure_leaf_nodes.pop(-1)\n",
    "            split_rules = {}\n",
    "            \n",
    "            # Find decision rule for parent node\n",
    "            data = parent_node.data\n",
    "            split_rule, cond_entropy = find_decision_rule(data)\n",
    "            parent_node.feature = split_rule[0]\n",
    "            parent_node.threshold = split_rule[1]\n",
    "            \n",
    "            # Define subsets based on splitting rule\n",
    "            right_split, left_split = split_threshold(parent_node.feature, parent_node.threshold, data)\n",
    "            \n",
    "            # Create child nodes \n",
    "            right_child_node = decisionTreeNode(right_split)\n",
    "            left_child_node = decisionTreeNode(left_split)\n",
    "            parent_node.children = [left_child_node, right_child_node]\n",
    "            \n",
    "            # Check Purity of Child Nodes\n",
    "            right_purity = right_child_node.isPure(label_index)\n",
    "            left_purity = left_child_node.isPure(label_index)\n",
    "            if right_purity == False: \n",
    "                # Add to impure nodes list\n",
    "                self.impure_leaf_nodes.append(right_child_node)\n",
    "            else: \n",
    "                # Add prediction label to leaf node\n",
    "                label_index = (right_child_node.data.shape[1] - 1)\n",
    "                right_child_node.pure = True\n",
    "                right_child_node.predicted_label = right_child_node.data[0,label_index]\n",
    "            if left_purity == False: \n",
    "                # Add to impure nodes list\n",
    "                self.impure_leaf_nodes.append(left_child_node)\n",
    "            else: \n",
    "                # Add prediction label to leaf node\n",
    "                label_index = (left_child_node.data.shape[1] - 1)\n",
    "                left_child_node.pure = True\n",
    "                left_child_node.predicted_label = left_child_node.data[0,label_index]\n",
    "    \n",
    "    def predict(self, data_point, node):\n",
    "        print(type(node))\n",
    "        # Base Case\n",
    "        if node.pure == True: \n",
    "            return node.predicted_label\n",
    "        # recurse to the left\n",
    "        if data_point[node.feature] < node.threshold: \n",
    "            print(\"Right\",type(node.children[0]))\n",
    "            self.predict(node.children[0], data_point)\n",
    "        # recurse to the right\n",
    "        elif data_point[node.feature] >= node.threshold: \n",
    "            print(\"Left\",type(node.children[1]))\n",
    "            self.predict(node.children[1], data_point)\n",
    "    \n",
    "    # Define Pruning Algorithm\n",
    "    def tree_pruning(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Feature and Threshold:  (1, 0.5)  Conditional Entropy:  0.2727917864120626\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0,1],[1,0,1],[1,1,0],[2,1,0],[2,0,0],[1,2,0],[2,2,0]])\n",
    "split_rule, info = find_decision_rule(test_data)\n",
    "print(\"Optimal Feature and Threshold: \", split_rule,' Conditional Entropy: ', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.decisionTreeNode'>\n",
      "Right <class '__main__.decisionTreeNode'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'pure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8f1cd14a4acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Label for (0,0,1): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-2b67a05c19da>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data_point, node)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Right\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# recurse to the right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2b67a05c19da>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data_point, node)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Base Case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# recurse to the left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pure'"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0,1],[1,0,1],[1,1,0],[2,1,0],[2,0,0],[1,2,0],[2,2,0]])\n",
    "dt = decisionTree(test_data)\n",
    "dt.train(test_data)\n",
    "print(\"Predicted Label for (0,0,1): \", dt.predict(np.array([0,0,1]), node=dt.root))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
